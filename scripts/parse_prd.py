#!/usr/bin/env python3
"""
PRD Parser - Product Requirements DocumentÎ•º ÏûëÏóÖ Î™©Î°ùÏúºÎ°ú Î≥ÄÌôò
"""

import re
import json
import yaml
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum
import click
from rich.console import Console
from rich.table import Table
from rich.tree import Tree
from rich.panel import Panel
from rich.progress import track

console = Console()

class RequirementType(Enum):
    FUNCTIONAL = "functional"
    NON_FUNCTIONAL = "non_functional"
    TECHNICAL = "technical"
    BUSINESS = "business"
    UX = "ux"

class Priority(Enum):
    CRITICAL = "P0"
    HIGH = "P1"
    MEDIUM = "P2"
    LOW = "P3"

@dataclass
class Requirement:
    """ÏöîÍµ¨ÏÇ¨Ìï≠ Îç∞Ïù¥ÌÑ∞ ÌÅ¥ÎûòÏä§"""
    id: str
    title: str
    description: str
    type: RequirementType
    priority: Priority
    acceptance_criteria: List[str]
    dependencies: List[str]
    estimated_hours: int
    tags: List[str]

@dataclass
class Epic:
    """ÏóêÌîΩ Îç∞Ïù¥ÌÑ∞ ÌÅ¥ÎûòÏä§"""
    id: str
    title: str
    description: str
    requirements: List[Requirement]
    priority: Priority
    milestone: Optional[str]

@dataclass
class Task:
    """ÏûëÏóÖ Îç∞Ïù¥ÌÑ∞ ÌÅ¥ÎûòÏä§"""
    id: str
    title: str
    description: str
    type: str
    priority: str
    estimated_hours: int
    dependencies: List[str]
    parent_id: Optional[str]
    tags: List[str]
    acceptance_criteria: List[str]
    status: str = "pending"

class PRDParser:
    """PRD Î¨∏ÏÑú ÌååÏÑú"""
    
    def __init__(self):
        self.epics: List[Epic] = []
        self.requirements: List[Requirement] = []
        self.tasks: List[Task] = []
        self.metadata: Dict = {}
        
    def parse_file(self, file_path: str) -> Dict:
        """PRD ÌååÏùº ÌååÏã±"""
        path = Path(file_path)
        
        if not path.exists():
            raise FileNotFoundError(f"PRD file not found: {file_path}")
        
        content = path.read_text(encoding='utf-8')
        
        # ÌååÏùº ÌòïÏãùÏóê Îî∞Îùº Îã§Î•∏ ÌååÏÑú ÏÇ¨Ïö©
        if path.suffix == '.md':
            return self.parse_markdown(content)
        elif path.suffix == '.txt':
            return self.parse_text(content)
        elif path.suffix in ['.yaml', '.yml']:
            return self.parse_yaml(content)
        elif path.suffix == '.json':
            return self.parse_json(content)
        else:
            # Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÌÖçÏä§Ìä∏Î°ú Ï≤òÎ¶¨
            return self.parse_text(content)
    
    def parse_markdown(self, content: str) -> Dict:
        """Markdown ÌòïÏãù PRD ÌååÏã±"""
        lines = content.split('\n')
        current_section = None
        current_epic = None
        current_requirement = None
        
        for line in lines:
            line = line.strip()
            
            # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
            if line.startswith('# '):
                self.metadata['title'] = line[2:].strip()
            
            # ÏóêÌîΩ Ï∂îÏ∂ú (## Epic:)
            elif line.startswith('## Epic:') or line.startswith('## ÏóêÌîΩ:'):
                epic_title = line.split(':', 1)[1].strip()
                current_epic = {
                    'id': f"EPIC-{len(self.epics) + 1}",
                    'title': epic_title,
                    'requirements': []
                }
                self.epics.append(current_epic)
            
            # ÏöîÍµ¨ÏÇ¨Ìï≠ Ï∂îÏ∂ú (### Requirement:)
            elif line.startswith('### Requirement:') or line.startswith('### ÏöîÍµ¨ÏÇ¨Ìï≠:'):
                req_title = line.split(':', 1)[1].strip()
                current_requirement = {
                    'id': f"REQ-{len(self.requirements) + 1}",
                    'title': req_title,
                    'description': '',
                    'acceptance_criteria': [],
                    'epic_id': current_epic['id'] if current_epic else None
                }
                self.requirements.append(current_requirement)
            
            # Ïö∞ÏÑ†ÏàúÏúÑ Ï∂îÏ∂ú
            elif line.startswith('Priority:') or line.startswith('Ïö∞ÏÑ†ÏàúÏúÑ:'):
                priority = line.split(':', 1)[1].strip()
                if current_requirement:
                    current_requirement['priority'] = self._parse_priority(priority)
            
            # Ïù∏Ïàò Ï°∞Í±¥ Ï∂îÏ∂ú
            elif line.startswith('- [ ]') or line.startswith('- [x]'):
                criteria = line[5:].strip()
                if current_requirement:
                    current_requirement['acceptance_criteria'].append(criteria)
            
            # ÌÉúÍ∑∏ Ï∂îÏ∂ú
            elif line.startswith('Tags:') or line.startswith('ÌÉúÍ∑∏:'):
                tags = line.split(':', 1)[1].strip()
                if current_requirement:
                    current_requirement['tags'] = [t.strip() for t in tags.split(',')]
        
        return self._convert_to_tasks()
    
    def parse_text(self, content: str) -> Dict:
        """ÌÖçÏä§Ìä∏ ÌòïÏãù PRD ÌååÏã±"""
        lines = content.split('\n')
        sections = {}
        current_section = None
        current_content = []
        
        for line in lines:
            # ÏÑπÏÖò Ìó§Îçî Í∞êÏßÄ
            if self._is_section_header(line):
                if current_section:
                    sections[current_section] = '\n'.join(current_content)
                current_section = line.strip().rstrip(':')
                current_content = []
            else:
                current_content.append(line)
        
        # ÎßàÏßÄÎßâ ÏÑπÏÖò Ï†ÄÏû•
        if current_section:
            sections[current_section] = '\n'.join(current_content)
        
        # ÏÑπÏÖòÎ≥ÑÎ°ú ÌååÏã±
        self._parse_sections(sections)
        
        return self._convert_to_tasks()
    
    def parse_yaml(self, content: str) -> Dict:
        """YAML ÌòïÏãù PRD ÌååÏã±"""
        data = yaml.safe_load(content)
        
        if 'metadata' in data:
            self.metadata = data['metadata']
        
        if 'epics' in data:
            for epic_data in data['epics']:
                self._parse_epic_data(epic_data)
        
        if 'requirements' in data:
            for req_data in data['requirements']:
                self._parse_requirement_data(req_data)
        
        return self._convert_to_tasks()
    
    def parse_json(self, content: str) -> Dict:
        """JSON ÌòïÏãù PRD ÌååÏã±"""
        data = json.loads(content)
        
        if 'metadata' in data:
            self.metadata = data['metadata']
        
        if 'epics' in data:
            for epic_data in data['epics']:
                self._parse_epic_data(epic_data)
        
        if 'requirements' in data:
            for req_data in data['requirements']:
                self._parse_requirement_data(req_data)
        
        return self._convert_to_tasks()
    
    def _is_section_header(self, line: str) -> bool:
        """ÏÑπÏÖò Ìó§ÎçîÏù∏ÏßÄ ÌôïÏù∏"""
        headers = [
            'Í∞úÏöî:', 'Overview:',
            'Î™©Ï†Å:', 'Purpose:',
            'ÏöîÍµ¨ÏÇ¨Ìï≠:', 'Requirements:',
            'Í∏∞Îä• ÏöîÍµ¨ÏÇ¨Ìï≠:', 'Functional Requirements:',
            'ÎπÑÍ∏∞Îä• ÏöîÍµ¨ÏÇ¨Ìï≠:', 'Non-Functional Requirements:',
            'Ï†úÏïΩÏÇ¨Ìï≠:', 'Constraints:',
            'Í∞ÄÏ†ï:', 'Assumptions:',
            'ÏúÑÌóò:', 'Risks:',
            'ÏùºÏ†ï:', 'Timeline:',
            'ÎßàÏùºÏä§ÌÜ§:', 'Milestones:'
        ]
        
        line = line.strip()
        return any(line.startswith(header) for header in headers)
    
    def _parse_sections(self, sections: Dict[str, str]):
        """ÏÑπÏÖòÎ≥Ñ ÎÇ¥Ïö© ÌååÏã±"""
        # ÏöîÍµ¨ÏÇ¨Ìï≠ ÏÑπÏÖò ÌååÏã±
        req_sections = [
            'ÏöîÍµ¨ÏÇ¨Ìï≠', 'Requirements',
            'Í∏∞Îä• ÏöîÍµ¨ÏÇ¨Ìï≠', 'Functional Requirements'
        ]
        
        for section_name in req_sections:
            if section_name in sections:
                self._parse_requirements_section(sections[section_name])
        
        # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
        if 'Í∞úÏöî' in sections or 'Overview' in sections:
            overview = sections.get('Í∞úÏöî', sections.get('Overview', ''))
            self.metadata['overview'] = overview.strip()
        
        if 'Î™©Ï†Å' in sections or 'Purpose' in sections:
            purpose = sections.get('Î™©Ï†Å', sections.get('Purpose', ''))
            self.metadata['purpose'] = purpose.strip()
    
    def _parse_requirements_section(self, content: str):
        """ÏöîÍµ¨ÏÇ¨Ìï≠ ÏÑπÏÖò ÌååÏã±"""
        lines = content.strip().split('\n')
        current_req = None
        
        for line in lines:
            line = line.strip()
            
            # Î≤àÌò∏Í∞Ä ÏûàÎäî ÏöîÍµ¨ÏÇ¨Ìï≠ (1. XXX, 1) XXX)
            if re.match(r'^\d+[\.\)]\s+', line):
                if current_req:
                    self.requirements.append(current_req)
                
                req_text = re.sub(r'^\d+[\.\)]\s+', '', line)
                current_req = {
                    'id': f"REQ-{len(self.requirements) + 1}",
                    'title': req_text,
                    'description': '',
                    'priority': 'P2',  # Í∏∞Î≥∏ Ïö∞ÏÑ†ÏàúÏúÑ
                    'type': 'functional',
                    'acceptance_criteria': [],
                    'tags': []
                }
            
            # ÌïòÏúÑ Ìï≠Î™© (-, *, ‚Ä¢)
            elif re.match(r'^[-\*‚Ä¢]\s+', line) and current_req:
                item = re.sub(r'^[-\*‚Ä¢]\s+', '', line)
                current_req['acceptance_criteria'].append(item)
            
            # ÏÑ§Î™Ö Ï∂îÍ∞Ä
            elif line and current_req:
                current_req['description'] += ' ' + line
        
        # ÎßàÏßÄÎßâ ÏöîÍµ¨ÏÇ¨Ìï≠ Ï†ÄÏû•
        if current_req:
            self.requirements.append(current_req)
    
    def _parse_priority(self, priority_text: str) -> str:
        """Ïö∞ÏÑ†ÏàúÏúÑ ÌÖçÏä§Ìä∏ ÌååÏã±"""
        priority_text = priority_text.lower()
        
        if any(word in priority_text for word in ['critical', 'Í∏¥Í∏â', 'ÌïÑÏàò', 'p0']):
            return 'P0'
        elif any(word in priority_text for word in ['high', 'ÎÜíÏùå', 'Ï§ëÏöî', 'p1']):
            return 'P1'
        elif any(word in priority_text for word in ['medium', 'Î≥¥ÌÜµ', 'Ï§ëÍ∞Ñ', 'p2']):
            return 'P2'
        elif any(word in priority_text for word in ['low', 'ÎÇÆÏùå', 'ÏÑ†ÌÉù', 'p3']):
            return 'P3'
        else:
            return 'P2'  # Í∏∞Î≥∏Í∞í
    
    def _parse_epic_data(self, epic_data: Dict):
        """ÏóêÌîΩ Îç∞Ïù¥ÌÑ∞ ÌååÏã±"""
        epic = {
            'id': epic_data.get('id', f"EPIC-{len(self.epics) + 1}"),
            'title': epic_data.get('title', 'Untitled Epic'),
            'description': epic_data.get('description', ''),
            'priority': epic_data.get('priority', 'P2'),
            'requirements': []
        }
        self.epics.append(epic)
        
        # ÏóêÌîΩ ÎÇ¥ ÏöîÍµ¨ÏÇ¨Ìï≠ ÌååÏã±
        if 'requirements' in epic_data:
            for req_data in epic_data['requirements']:
                req_data['epic_id'] = epic['id']
                self._parse_requirement_data(req_data)
    
    def _parse_requirement_data(self, req_data: Dict):
        """ÏöîÍµ¨ÏÇ¨Ìï≠ Îç∞Ïù¥ÌÑ∞ ÌååÏã±"""
        requirement = {
            'id': req_data.get('id', f"REQ-{len(self.requirements) + 1}"),
            'title': req_data.get('title', 'Untitled Requirement'),
            'description': req_data.get('description', ''),
            'type': req_data.get('type', 'functional'),
            'priority': req_data.get('priority', 'P2'),
            'acceptance_criteria': req_data.get('acceptance_criteria', []),
            'dependencies': req_data.get('dependencies', []),
            'estimated_hours': req_data.get('estimated_hours', 0),
            'tags': req_data.get('tags', []),
            'epic_id': req_data.get('epic_id')
        }
        self.requirements.append(requirement)
    
    def _convert_to_tasks(self) -> Dict:
        """ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÏûëÏóÖÏúºÎ°ú Î≥ÄÌôò"""
        tasks = []
        
        # ÏóêÌîΩÏùÑ PhaseÎ°ú Î≥ÄÌôò
        for epic in self.epics:
            phase_task = Task(
                id=epic['id'],
                title=epic['title'],
                description=epic.get('description', ''),
                type='phase',
                priority=epic.get('priority', 'P2'),
                estimated_hours=0,
                dependencies=[],
                parent_id=None,
                tags=['epic'],
                acceptance_criteria=[]
            )
            tasks.append(phase_task)
        
        # ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ TaskÎ°ú Î≥ÄÌôò
        for req in self.requirements:
            # Î©îÏù∏ ÌÉúÏä§ÌÅ¨ ÏÉùÏÑ±
            main_task = Task(
                id=req['id'],
                title=req['title'],
                description=req.get('description', ''),
                type=req.get('type', 'functional'),
                priority=req.get('priority', 'P2'),
                estimated_hours=req.get('estimated_hours', 8),
                dependencies=req.get('dependencies', []),
                parent_id=req.get('epic_id'),
                tags=req.get('tags', []),
                acceptance_criteria=req.get('acceptance_criteria', [])
            )
            tasks.append(main_task)
            
            # Ïù∏Ïàò Ï°∞Í±¥ÏùÑ ÏÑúÎ∏åÌÉúÏä§ÌÅ¨Î°ú Î≥ÄÌôò
            for i, criteria in enumerate(req.get('acceptance_criteria', [])):
                sub_task = Task(
                    id=f"{req['id']}-{i+1}",
                    title=criteria,
                    description=f"Acceptance criteria for {req['title']}",
                    type='subtask',
                    priority=req.get('priority', 'P2'),
                    estimated_hours=2,
                    dependencies=[],
                    parent_id=req['id'],
                    tags=['acceptance_criteria'],
                    acceptance_criteria=[]
                )
                tasks.append(sub_task)
        
        return {
            'metadata': self.metadata,
            'epics': self.epics,
            'requirements': self.requirements,
            'tasks': [asdict(task) for task in tasks],
            'statistics': self._calculate_statistics(tasks)
        }
    
    def _calculate_statistics(self, tasks: List[Task]) -> Dict:
        """ÌÜµÍ≥Ñ Í≥ÑÏÇ∞"""
        total_tasks = len(tasks)
        total_hours = sum(task.estimated_hours for task in tasks)
        
        priority_count = {}
        type_count = {}
        
        for task in tasks:
            # Ïö∞ÏÑ†ÏàúÏúÑÎ≥Ñ Ïπ¥Ïö¥Ìä∏
            priority = task.priority
            priority_count[priority] = priority_count.get(priority, 0) + 1
            
            # ÌÉÄÏûÖÎ≥Ñ Ïπ¥Ïö¥Ìä∏
            task_type = task.type
            type_count[task_type] = type_count.get(task_type, 0) + 1
        
        return {
            'total_tasks': total_tasks,
            'total_hours': total_hours,
            'total_days': total_hours / 8,  # 8ÏãúÍ∞Ñ = 1Ïùº
            'priority_distribution': priority_count,
            'type_distribution': type_count
        }

class TaskGenerator:
    """ÏûëÏóÖ ÏÉùÏÑ±Í∏∞"""
    
    def __init__(self, parsed_data: Dict):
        self.data = parsed_data
        
    def generate_taskmaster_format(self) -> Dict:
        """Taskmaster ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò"""
        phases = []
        
        # ÏóêÌîΩÎ≥ÑÎ°ú Phase ÏÉùÏÑ±
        for epic in self.data.get('epics', []):
            phase = {
                'id': epic['id'],
                'name': epic['title'],
                'status': 'pending',
                'priority': epic.get('priority', 'P2'),
                'progress': 0,
                'tasks': []
            }
            
            # Ìï¥Îãπ ÏóêÌîΩÏùò ÌÉúÏä§ÌÅ¨ Ï∞æÍ∏∞
            for task in self.data.get('tasks', []):
                if task.get('parent_id') == epic['id']:
                    phase['tasks'].append({
                        'id': task['id'],
                        'name': task['title'],
                        'status': 'pending',
                        'estimated_hours': task.get('estimated_hours', 8),
                        'dependencies': task.get('dependencies', [])
                    })
            
            phases.append(phase)
        
        # ÏóêÌîΩÏù¥ ÏóÜÎäî ÌÉúÏä§ÌÅ¨Îì§ÏùÑ Î≥ÑÎèÑ PhaseÎ°ú
        orphan_tasks = []
        for task in self.data.get('tasks', []):
            if not task.get('parent_id') and task['type'] != 'phase':
                orphan_tasks.append({
                    'id': task['id'],
                    'name': task['title'],
                    'status': 'pending',
                    'estimated_hours': task.get('estimated_hours', 8),
                    'dependencies': task.get('dependencies', [])
                })
        
        if orphan_tasks:
            phases.append({
                'id': 'general',
                'name': 'üìã General Requirements',
                'status': 'pending',
                'priority': 'P2',
                'progress': 0,
                'tasks': orphan_tasks
            })
        
        return {
            'project': self.data.get('metadata', {}).get('title', 'Untitled Project'),
            'version': '0.1.0',
            'created': datetime.now().isoformat(),
            'metadata': self.data.get('metadata', {}),
            'phases': phases,
            'statistics': self.data.get('statistics', {})
        }
    
    def generate_jira_format(self) -> List[Dict]:
        """JIRA ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò"""
        jira_issues = []
        
        for task in self.data.get('tasks', []):
            issue = {
                'project': 'AUTOINPUT',
                'summary': task['title'],
                'description': task['description'],
                'issuetype': self._map_to_jira_type(task['type']),
                'priority': self._map_to_jira_priority(task['priority']),
                'labels': task.get('tags', []),
                'timeoriginalestimate': f"{task.get('estimated_hours', 8)}h",
                'acceptance_criteria': task.get('acceptance_criteria', [])
            }
            
            if task.get('parent_id'):
                issue['parent'] = task['parent_id']
            
            jira_issues.append(issue)
        
        return jira_issues
    
    def _map_to_jira_type(self, task_type: str) -> str:
        """JIRA Ïù¥Ïäà ÌÉÄÏûÖÏúºÎ°ú Îß§Ìïë"""
        type_mapping = {
            'phase': 'Epic',
            'functional': 'Story',
            'technical': 'Task',
            'bug': 'Bug',
            'subtask': 'Sub-task'
        }
        return type_mapping.get(task_type, 'Task')
    
    def _map_to_jira_priority(self, priority: str) -> str:
        """JIRA Ïö∞ÏÑ†ÏàúÏúÑÎ°ú Îß§Ìïë"""
        priority_mapping = {
            'P0': 'Highest',
            'P1': 'High',
            'P2': 'Medium',
            'P3': 'Low'
        }
        return priority_mapping.get(priority, 'Medium')
    
    def generate_github_issues(self) -> List[Dict]:
        """GitHub Issues ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò"""
        issues = []
        
        for task in self.data.get('tasks', []):
            issue = {
                'title': task['title'],
                'body': self._generate_github_body(task),
                'labels': self._generate_github_labels(task),
                'milestone': None
            }
            
            # ÏóêÌîΩÏùÑ ÎßàÏùºÏä§ÌÜ§ÏúºÎ°ú ÏÇ¨Ïö©
            if task.get('parent_id'):
                issue['milestone'] = task['parent_id']
            
            issues.append(issue)
        
        return issues
    
    def _generate_github_body(self, task: Dict) -> str:
        """GitHub Ïù¥Ïäà Î≥∏Î¨∏ ÏÉùÏÑ±"""
        body = f"## Description\n{task['description']}\n\n"
        
        if task.get('acceptance_criteria'):
            body += "## Acceptance Criteria\n"
            for criteria in task['acceptance_criteria']:
                body += f"- [ ] {criteria}\n"
            body += "\n"
        
        if task.get('dependencies'):
            body += "## Dependencies\n"
            for dep in task['dependencies']:
                body += f"- #{dep}\n"
            body += "\n"
        
        if task.get('estimated_hours'):
            body += f"## Estimated Time\n{task['estimated_hours']} hours\n"
        
        return body
    
    def _generate_github_labels(self, task: Dict) -> List[str]:
        """GitHub ÎùºÎ≤® ÏÉùÏÑ±"""
        labels = task.get('tags', []).copy()
        
        # Ïö∞ÏÑ†ÏàúÏúÑ ÎùºÎ≤®
        priority_labels = {
            'P0': 'priority: critical',
            'P1': 'priority: high',
            'P2': 'priority: medium',
            'P3': 'priority: low'
        }
        if task.get('priority') in priority_labels:
            labels.append(priority_labels[task['priority']])
        
        # ÌÉÄÏûÖ ÎùºÎ≤®
        type_labels = {
            'functional': 'type: feature',
            'technical': 'type: technical',
            'bug': 'type: bug',
            'documentation': 'type: docs'
        }
        if task.get('type') in type_labels:
            labels.append(type_labels[task['type']])
        
        return labels

@click.command()
@click.argument('prd_file', type=click.Path(exists=True))
@click.option('--output', '-o', default='tasks.json', help='Output file name')
@click.option('--format', '-f', type=click.Choice(['taskmaster', 'jira', 'github']), 
              default='taskmaster', help='Output format')
@click.option('--verbose', '-v', is_flag=True, help='Verbose output')
def parse_prd(prd_file: str, output: str, format: str, verbose: bool):
    """PRD Î¨∏ÏÑúÎ•º ÌååÏã±ÌïòÏó¨ ÏûëÏóÖ Î™©Î°ùÏúºÎ°ú Î≥ÄÌôò"""
    
    console.print(f"[cyan]üìÑ Parsing PRD: {prd_file}[/cyan]")
    
    # PRD ÌååÏã±
    parser = PRDParser()
    
    try:
        parsed_data = parser.parse_file(prd_file)
        
        if verbose:
            # ÌååÏã± Í≤∞Í≥º ÌëúÏãú
            stats = parsed_data.get('statistics', {})
            
            panel = Panel(
                f"‚úÖ Successfully parsed PRD\n\n"
                f"üìä Statistics:\n"
                f"  ‚Ä¢ Total Tasks: {stats.get('total_tasks', 0)}\n"
                f"  ‚Ä¢ Total Hours: {stats.get('total_hours', 0)}\n"
                f"  ‚Ä¢ Estimated Days: {stats.get('total_days', 0):.1f}\n",
                title="[bold green]Parsing Complete[/bold green]",
                border_style="green"
            )
            console.print(panel)
            
            # Ïö∞ÏÑ†ÏàúÏúÑ Î∂ÑÌè¨
            if stats.get('priority_distribution'):
                table = Table(title="Priority Distribution")
                table.add_column("Priority", style="cyan")
                table.add_column("Count", justify="right")
                
                for priority, count in stats['priority_distribution'].items():
                    table.add_row(priority, str(count))
                
                console.print(table)
        
        # ÏûëÏóÖ ÏÉùÏÑ±
        generator = TaskGenerator(parsed_data)
        
        if format == 'taskmaster':
            output_data = generator.generate_taskmaster_format()
            output_file = output if output.endswith('.json') else f"{output}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            console.print(f"[green]‚úÖ Taskmaster format saved to {output_file}[/green]")
            
        elif format == 'jira':
            output_data = generator.generate_jira_format()
            output_file = output if output.endswith('.json') else f"{output}_jira.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            console.print(f"[green]‚úÖ JIRA format saved to {output_file}[/green]")
            
        elif format == 'github':
            output_data = generator.generate_github_issues()
            output_file = output if output.endswith('.json') else f"{output}_github.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            console.print(f"[green]‚úÖ GitHub Issues format saved to {output_file}[/green]")
        
        # ÏûëÏóÖ Ìä∏Î¶¨ ÌëúÏãú
        if verbose:
            tree = Tree("üìã [bold cyan]Generated Task Tree[/bold cyan]")
            
            taskmaster_data = generator.generate_taskmaster_format()
            for phase in taskmaster_data['phases']:
                phase_node = tree.add(f"üì¶ {phase['name']} ({len(phase['tasks'])} tasks)")
                
                for task in phase['tasks'][:5]:  # Ï≤òÏùå 5Í∞úÎßå ÌëúÏãú
                    phase_node.add(f"‚Ä¢ {task['name']}")
                
                if len(phase['tasks']) > 5:
                    phase_node.add(f"... and {len(phase['tasks']) - 5} more")
            
            console.print(tree)
    
    except Exception as e:
        console.print(f"[red]‚ùå Error parsing PRD: {e}[/red]")
        raise

if __name__ == "__main__":
    parse_prd()