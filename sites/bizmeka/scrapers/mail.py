#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
BizmekaMailScraper - ë¹„ì¦ˆë©”ì¹´ ë©”ì¼ ìŠ¤í¬ë˜í¼
ê¸°ì¡´ì˜ ì—¬ëŸ¬ ë²„ì „ë“¤ì„ í†µí•©í•œ ìµœì¢… ì™„ì„± ë²„ì „
"""

from typing import List, Dict, Any
from datetime import datetime
from playwright.async_api import Page

from core.base.scraper import BaseScraper


class BizmekaMailScraper(BaseScraper):
    """ë¹„ì¦ˆë©”ì¹´ ë©”ì¼ ìŠ¤í¬ë˜í¼"""
    
    def __init__(self):
        super().__init__('bizmeka')
        self.selectors = self._load_selectors()
    
    async def scrape(self, max_pages: int = 3) -> List[Dict[str, Any]]:
        """ë©”ì¼ ìŠ¤í¬ë˜í•‘ ë©”ì¸ ë¡œì§"""
        if not self.page:
            raise ValueError("Page not initialized. Call setup_browser first.")
        
        self.log("ë©”ì¼ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
        all_mails = []
        
        # ë©”ì¼ ì‹œìŠ¤í…œ ì ‘ì†
        await self._navigate_to_mail_system()
        
        # ë°›ì€ë©”ì¼í•¨ ì ‘ì†
        await self._navigate_to_inbox()
        
        # í˜ì´ì§€ë³„ ë©”ì¼ ìˆ˜ì§‘
        for page_num in range(1, max_pages + 1):
            self.log(f"í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘...")
            
            # íŒì—… ì²˜ë¦¬
            await self.close_popups()
            
            # ë©”ì¼ ë°ì´í„° ì¶”ì¶œ
            page_mails = await self._extract_mails_from_page(page_num)
            all_mails.extend(page_mails)
            
            self.log(f"í˜ì´ì§€ {page_num}: {len(page_mails)}ê°œ ë©”ì¼ ìˆ˜ì§‘")
            
            # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
            if page_num < max_pages:
                success = await self._navigate_to_next_page(page_num + 1)
                if not success:
                    self.log(f"í˜ì´ì§€ {page_num}ê¹Œì§€ë§Œ ìˆ˜ì§‘ ê°€ëŠ¥")
                    break
        
        self.log(f"ì´ {len(all_mails)}ê°œ ë©”ì¼ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_mails
    
    async def _navigate_to_mail_system(self):
        """ë©”ì¼ ì‹œìŠ¤í…œ ì ‘ì†"""
        mail_link = await self.page.query_selector('a[href*="mail"]')
        if mail_link:
            await mail_link.click()
            await self.page.wait_for_timeout(3000)
            
            # ìƒˆ íƒ­ìœ¼ë¡œ ì „í™˜
            if len(self.context.pages) > 1:
                self.page = self.context.pages[-1]
                self.log("ìƒˆ íƒ­ìœ¼ë¡œ ì „í™˜")
    
    async def _navigate_to_inbox(self):
        """ë°›ì€ë©”ì¼í•¨ ì ‘ì†"""
        await self.close_popups()
        
        # ë™ì  ì„ íƒìë¡œ ë°›ì€ë©”ì¼í•¨ ì°¾ê¸°
        inbox_selectors = [
            '[id^="mnu_Inbox_"]',  # ê°€ì¥ ì •í™•í•œ ì„ íƒì
            'a[onclick*="Inbox"]',
            'a:has-text("ë°›ì€ë©”ì¼í•¨")',
            '.mbutton:has-text("ë°›ì€ë©”ì¼í•¨")'
        ]
        
        for selector in inbox_selectors:
            try:
                inbox = await self.page.query_selector(selector)
                if inbox:
                    await inbox.click()
                    self.log("ë°›ì€ë©”ì¼í•¨ ì ‘ì† ì™„ë£Œ")
                    await self.page.wait_for_timeout(3000)
                    break
            except:
                continue
        
        # íŒì—… ë‹¤ì‹œ ì²˜ë¦¬
        await self.close_popups()
    
    async def _extract_mails_from_page(self, page_num: int) -> List[Dict[str, Any]]:
        """í˜ì´ì§€ì—ì„œ ë©”ì¼ ì¶”ì¶œ"""
        page_mails = []
        
        try:
            # í”„ë ˆì„ í™•ì¸
            target_page = self.page
            for frame in self.page.frames:
                if 'mail' in frame.url.lower():
                    target_page = frame
                    break
            
            # li.m_data ìš”ì†Œë“¤ ì°¾ê¸°
            mail_items = await target_page.query_selector_all('li.m_data')
            
            for i, item in enumerate(mail_items):
                try:
                    # ì†ì„±ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                    from_name = await item.get_attribute('data-fromname') or ''
                    from_addr = await item.get_attribute('data-fromaddr') or ''
                    mail_id = await item.get_attribute('data-key') or ''
                    
                    # ì œëª© ì¶”ì¶œ
                    subject = ''
                    subject_elem = await item.query_selector('p.m_subject')
                    if subject_elem:
                        subject_text = await subject_elem.inner_text()
                        # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
                        subject = self._clean_subject(subject_text)
                    
                    # ë‚ ì§œì™€ í¬ê¸° ì¶”ì¶œ
                    date = ''
                    size = ''
                    date_elem = await item.query_selector('span.m_date')
                    size_elem = await item.query_selector('span.m_size')
                    
                    if date_elem:
                        date = await date_elem.inner_text()
                    if size_elem:
                        size = await size_elem.inner_text()
                    
                    # ì½ìŒ ìƒíƒœ
                    item_class = await item.get_attribute('class') or ''
                    is_unread = 'unread' in item_class
                    
                    # ë°ì´í„° êµ¬ì„±
                    mail_data = {
                        'í˜ì´ì§€': page_num,
                        'ìˆœë²ˆ': i + 1,
                        'ë©”ì¼ID': mail_id,
                        'ë³´ë‚¸ì‚¬ëŒ': from_name.strip(),
                        'ì´ë©”ì¼ì£¼ì†Œ': from_addr.strip(),
                        'ì œëª©': subject.strip(),
                        'ë‚ ì§œ': date.strip(),
                        'í¬ê¸°': size.strip(),
                        'ì½ìŒìƒíƒœ': 'ì•ˆì½ìŒ' if is_unread else 'ì½ìŒ',
                        'ìˆ˜ì§‘ì‹œê°„': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }
                    
                    if mail_data['ë³´ë‚¸ì‚¬ëŒ'] or mail_data['ì œëª©']:
                        page_mails.append(mail_data)
                
                except Exception as e:
                    self.log(f"ë©”ì¼ í•­ëª© {i} ì²˜ë¦¬ ì˜¤ë¥˜: {e}", "WARNING")
                    continue
        
        except Exception as e:
            self.log(f"ë©”ì¼ ì¶”ì¶œ ì˜¤ë¥˜: {e}", "ERROR")
        
        return page_mails
    
    def _clean_subject(self, subject_text: str) -> str:
        """ì œëª© í…ìŠ¤íŠ¸ ì •ë¦¬"""
        # ì´ëª¨ì§€ì™€ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        subject = subject_text.strip()
        subject = subject.replace('ğŸŒ…', '').replace('&nbsp;', ' ')
        subject = subject.replace('\n', ' ').replace('\t', ' ')
        
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        while '  ' in subject:
            subject = subject.replace('  ', ' ')
        
        return subject.strip()
    
    async def _navigate_to_next_page(self, page_num: int) -> bool:
        """ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™"""
        try:
            await self.close_popups()
            
            # í˜ì´ì§€ ë²ˆí˜¸ ë§í¬ ì°¾ê¸°
            page_selectors = [
                f'a:has-text("{page_num}")',
                f'[onclick*="page={page_num}"]',
                f'.pagination a:has-text("{page_num}")'
            ]
            
            for selector in page_selectors:
                try:
                    page_link = await self.page.query_selector(selector)
                    if page_link:
                        await page_link.click()
                        self.log(f"{page_num}í˜ì´ì§€ë¡œ ì´ë™")
                        await self.page.wait_for_timeout(3000)
                        return True
                except:
                    continue
            
            return False
            
        except Exception as e:
            self.log(f"í˜ì´ì§€ ì´ë™ ì˜¤ë¥˜: {e}", "ERROR")
            return False
    
    async def scrape_and_save(self, max_pages: int = 3, filename: str = None) -> str:
        """ìŠ¤í¬ë˜í•‘ í›„ Excelë¡œ ì €ì¥"""
        mails = await self.scrape(max_pages)
        
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"bizmeka_mails_{timestamp}.xlsx"
        
        filepath = self.save_data_to_excel(mails, filename)
        self.log(f"Excel ì €ì¥ ì™„ë£Œ: {filepath}")
        
        return filepath