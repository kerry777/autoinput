# -*- coding: utf-8 -*-
"""
GraphQL ìŠ¤í¬ë˜í•‘ ì „ë¬¸ ëª¨ë“ˆ
"""
import requests
import json
from typing import Dict, List, Any, Optional
import hashlib
import time
from dataclasses import dataclass

@dataclass
class GraphQLQuery:
    """GraphQL ì¿¼ë¦¬ ê°ì²´"""
    query: str
    variables: Dict = None
    operation_name: str = None

class GraphQLScraper:
    """GraphQL API ìŠ¤í¬ë˜í•‘ ì „ë¬¸ í´ë˜ìŠ¤"""
    
    def __init__(self, endpoint: str):
        self.endpoint = endpoint
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json',
            'Accept': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.query_cache = {}
    
    def execute_query(self, query: GraphQLQuery) -> Dict:
        """GraphQL ì¿¼ë¦¬ ì‹¤í–‰"""
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self._generate_cache_key(query)
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.query_cache:
            print(f"ğŸ“¦ ìºì‹œì—ì„œ ë¡œë“œ: {cache_key[:8]}...")
            return self.query_cache[cache_key]
        
        # ìš”ì²­ í˜ì´ë¡œë“œ êµ¬ì„±
        payload = {
            'query': query.query
        }
        
        if query.variables:
            payload['variables'] = query.variables
        
        if query.operation_name:
            payload['operationName'] = query.operation_name
        
        # ìš”ì²­ ì‹¤í–‰
        try:
            response = self.session.post(
                self.endpoint,
                json=payload
            )
            response.raise_for_status()
            
            data = response.json()
            
            # ì—ëŸ¬ ì²´í¬
            if 'errors' in data:
                print(f"âš ï¸ GraphQL ì—ëŸ¬: {data['errors']}")
            
            # ìºì‹œ ì €ì¥
            self.query_cache[cache_key] = data
            
            return data
            
        except Exception as e:
            print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {}
    
    def _generate_cache_key(self, query: GraphQLQuery) -> str:
        """ì¿¼ë¦¬ ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{query.query}{json.dumps(query.variables or {})}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def introspect_schema(self) -> Dict:
        """GraphQL ìŠ¤í‚¤ë§ˆ ìë™ íƒìƒ‰"""
        introspection_query = GraphQLQuery(
            query="""
            query IntrospectionQuery {
                __schema {
                    types {
                        name
                        kind
                        description
                        fields {
                            name
                            type {
                                name
                                kind
                            }
                        }
                    }
                    queryType {
                        name
                        fields {
                            name
                            description
                            args {
                                name
                                type {
                                    name
                                }
                            }
                        }
                    }
                    mutationType {
                        name
                    }
                }
            }
            """
        )
        
        return self.execute_query(introspection_query)
    
    def paginate_query(self, base_query: str, page_size: int = 20, max_pages: int = None) -> List[Dict]:
        """í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬"""
        all_results = []
        has_next_page = True
        cursor = None
        page = 0
        
        while has_next_page:
            if max_pages and page >= max_pages:
                break
            
            # ì»¤ì„œ ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜ ì¿¼ë¦¬
            variables = {
                'first': page_size,
                'after': cursor
            }
            
            query = GraphQLQuery(
                query=base_query,
                variables=variables
            )
            
            result = self.execute_query(query)
            
            if 'data' in result:
                # ë°ì´í„° ì¶”ì¶œ (êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
                edges = self._extract_edges(result['data'])
                all_results.extend(edges)
                
                # í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
                page_info = self._extract_page_info(result['data'])
                has_next_page = page_info.get('hasNextPage', False)
                cursor = page_info.get('endCursor')
                
                print(f"ğŸ“„ í˜ì´ì§€ {page + 1}: {len(edges)}ê°œ í•­ëª©")
            else:
                break
            
            page += 1
            time.sleep(0.5)  # Rate limiting
        
        return all_results
    
    def _extract_edges(self, data: Dict) -> List:
        """ì—£ì§€ ë°ì´í„° ì¶”ì¶œ"""
        # ì¼ë°˜ì ì¸ GraphQL êµ¬ì¡° íƒìƒ‰
        for key, value in data.items():
            if isinstance(value, dict):
                if 'edges' in value:
                    return value['edges']
                elif 'nodes' in value:
                    return value['nodes']
                else:
                    # ì¬ê·€ì  íƒìƒ‰
                    result = self._extract_edges(value)
                    if result:
                        return result
        
        return []
    
    def _extract_page_info(self, data: Dict) -> Dict:
        """í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ"""
        for key, value in data.items():
            if isinstance(value, dict):
                if 'pageInfo' in value:
                    return value['pageInfo']
                else:
                    result = self._extract_page_info(value)
                    if result:
                        return result
        
        return {}
    
    def batch_query(self, queries: List[GraphQLQuery]) -> List[Dict]:
        """ë°°ì¹˜ ì¿¼ë¦¬ ì‹¤í–‰"""
        results = []
        
        for query in queries:
            result = self.execute_query(query)
            results.append(result)
            time.sleep(0.1)  # Rate limiting
        
        return results
    
    def subscribe_to_updates(self, subscription_query: str):
        """GraphQL êµ¬ë… (WebSocket í•„ìš”)"""
        # ì‹¤ì œ êµ¬í˜„ì€ websocket-client ë˜ëŠ” graphql-ws í•„ìš”
        print("âš ï¸ êµ¬ë… ê¸°ëŠ¥ì€ WebSocket ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤")
        pass

class GraphQLAnalyzer:
    """GraphQL API ë¶„ì„ ë„êµ¬"""
    
    def __init__(self, scraper: GraphQLScraper):
        self.scraper = scraper
    
    def analyze_api(self) -> Dict:
        """API êµ¬ì¡° ë¶„ì„"""
        print("\nğŸ” GraphQL API ë¶„ì„ ì¤‘...")
        
        # ìŠ¤í‚¤ë§ˆ íƒìƒ‰
        schema = self.scraper.introspect_schema()
        
        analysis = {
            'types': [],
            'queries': [],
            'mutations': [],
            'subscriptions': []
        }
        
        if 'data' in schema and '__schema' in schema['data']:
            schema_data = schema['data']['__schema']
            
            # íƒ€ì… ë¶„ì„
            for type_info in schema_data.get('types', []):
                if not type_info['name'].startswith('__'):
                    analysis['types'].append({
                        'name': type_info['name'],
                        'kind': type_info['kind'],
                        'fields': len(type_info.get('fields', []) or [])
                    })
            
            # ì¿¼ë¦¬ ë¶„ì„
            if schema_data.get('queryType'):
                query_type = schema_data['queryType']
                for field in query_type.get('fields', []):
                    analysis['queries'].append({
                        'name': field['name'],
                        'description': field.get('description', ''),
                        'args': [arg['name'] for arg in field.get('args', [])]
                    })
        
        return analysis
    
    def find_pagination_pattern(self, sample_query_result: Dict) -> str:
        """í˜ì´ì§€ë„¤ì´ì…˜ íŒ¨í„´ ìë™ ê°ì§€"""
        patterns = []
        
        def search_pattern(obj, path=""):
            if isinstance(obj, dict):
                if 'pageInfo' in obj:
                    patterns.append(f"{path}.pageInfo")
                if 'edges' in obj and 'nodes' in obj:
                    patterns.append(f"{path} (Relay pattern)")
                if 'hasNextPage' in obj or 'endCursor' in obj:
                    patterns.append(f"{path} (Cursor-based)")
                if 'page' in obj or 'totalPages' in obj:
                    patterns.append(f"{path} (Page-based)")
                
                for key, value in obj.items():
                    search_pattern(value, f"{path}.{key}" if path else key)
            elif isinstance(obj, list) and obj:
                search_pattern(obj[0], f"{path}[0]")
        
        search_pattern(sample_query_result)
        
        if patterns:
            print(f"âœ… í˜ì´ì§€ë„¤ì´ì…˜ íŒ¨í„´ ë°œê²¬: {patterns[0]}")
            return patterns[0]
        else:
            print("âŒ í˜ì´ì§€ë„¤ì´ì…˜ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return ""

# ì‹¤ì „ ì˜ˆì œ: ì „ììƒê±°ë˜ GraphQL API
class EcommerceGraphQLScraper:
    """ì „ììƒê±°ë˜ íŠ¹í™” GraphQL ìŠ¤í¬ë˜í¼"""
    
    def __init__(self, endpoint: str):
        self.scraper = GraphQLScraper(endpoint)
    
    def get_products(self, category_id: str = None, limit: int = 100) -> List[Dict]:
        """ì œí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        query = """
        query GetProducts($first: Int!, $after: String, $categoryId: ID) {
            products(first: $first, after: $after, categoryId: $categoryId) {
                edges {
                    node {
                        id
                        name
                        price
                        description
                        images {
                            url
                        }
                        category {
                            id
                            name
                        }
                        inventory {
                            available
                        }
                        reviews {
                            rating
                            count
                        }
                    }
                }
                pageInfo {
                    hasNextPage
                    endCursor
                }
                totalCount
            }
        }
        """
        
        return self.scraper.paginate_query(query, page_size=20, max_pages=limit//20)
    
    def get_product_details(self, product_id: str) -> Dict:
        """ì œí’ˆ ìƒì„¸ ì •ë³´"""
        query = GraphQLQuery(
            query="""
            query GetProductDetails($id: ID!) {
                product(id: $id) {
                    id
                    name
                    price
                    originalPrice
                    description
                    specifications {
                        key
                        value
                    }
                    images {
                        url
                        alt
                    }
                    variants {
                        id
                        name
                        price
                        available
                    }
                    relatedProducts {
                        id
                        name
                        price
                        image
                    }
                }
            }
            """,
            variables={'id': product_id}
        )
        
        return self.scraper.execute_query(query)
    
    def search_products(self, query_text: str, filters: Dict = None) -> List[Dict]:
        """ì œí’ˆ ê²€ìƒ‰"""
        query = GraphQLQuery(
            query="""
            query SearchProducts($query: String!, $filters: ProductFilters) {
                search(query: $query, filters: $filters) {
                    products {
                        id
                        name
                        price
                        image
                        relevanceScore
                    }
                    facets {
                        category {
                            name
                            count
                        }
                        priceRange {
                            min
                            max
                        }
                        brands {
                            name
                            count
                        }
                    }
                    totalResults
                }
            }
            """,
            variables={
                'query': query_text,
                'filters': filters or {}
            }
        )
        
        result = self.scraper.execute_query(query)
        return result.get('data', {}).get('search', {}).get('products', [])

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    print("ğŸš€ GraphQL ìŠ¤í¬ë˜í•‘ ê³ ê¸‰ ê¸°ë²•")
    print("=" * 80)
    
    # web-scraping.dev GraphQL ì—”ë“œí¬ì¸íŠ¸ (ì˜ˆì œ)
    endpoint = "https://web-scraping.dev/api/graphql"
    
    # GraphQL ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
    scraper = GraphQLScraper(endpoint)
    
    # 1. ìŠ¤í‚¤ë§ˆ íƒìƒ‰
    print("\nğŸ“Š ìŠ¤í‚¤ë§ˆ íƒìƒ‰:")
    schema = scraper.introspect_schema()
    if schema:
        print("  âœ… ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
    
    # 2. ê°„ë‹¨í•œ ì¿¼ë¦¬ ì‹¤í–‰
    print("\nğŸ“¡ ì¿¼ë¦¬ ì‹¤í–‰:")
    simple_query = GraphQLQuery(
        query="""
        query {
            products(first: 5) {
                edges {
                    node {
                        id
                        name
                        price
                    }
                }
            }
        }
        """
    )
    
    result = scraper.execute_query(simple_query)
    if result:
        print(f"  âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì„±ê³µ")
    
    # 3. API ë¶„ì„
    analyzer = GraphQLAnalyzer(scraper)
    analysis = analyzer.analyze_api()
    
    print(f"\nğŸ“ˆ API ë¶„ì„ ê²°ê³¼:")
    print(f"  â€¢ íƒ€ì…: {len(analysis['types'])}ê°œ")
    print(f"  â€¢ ì¿¼ë¦¬: {len(analysis['queries'])}ê°œ")
    print(f"  â€¢ ë®¤í…Œì´ì…˜: {len(analysis['mutations'])}ê°œ")
    
    print("\nâœ¨ GraphQL ìŠ¤í¬ë˜í•‘ ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ!")